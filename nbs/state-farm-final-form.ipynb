{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aviary 0.0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path = \"data/state-farm/\"\n",
    "path = \"data/state-farm/sample/\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Set up batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filename) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                                 shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Load data from images (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "trn = get_data(path+'train')\n",
    "val = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load/Save data with array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/val.dat', val)\n",
    "save_array(path+'results/trn.dat', trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = load_array(path+'results/val.dat')\n",
    "trn = load_array(path+'results/trn.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.1),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=8, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=12, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=16, validation_data=val_batches, \n",
    "                         nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 1\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=16, validation_data=val_batches, \n",
    "                         nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Run 0.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 34s - loss: 2.9844 - acc: 0.1253 - val_loss: 2.3778 - val_acc: 0.1040\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 28s - loss: 2.7432 - acc: 0.1560 - val_loss: 2.2816 - val_acc: 0.1530\n",
      "Epoch 1/8\n",
      "1500/1500 [==============================] - 34s - loss: 2.4548 - acc: 0.2040 - val_loss: 2.4117 - val_acc: 0.1620\n",
      "Epoch 2/8\n",
      "1500/1500 [==============================] - 26s - loss: 2.3739 - acc: 0.2233 - val_loss: 2.5295 - val_acc: 0.1730\n",
      "Epoch 3/8\n",
      "1500/1500 [==============================] - 32s - loss: 2.1661 - acc: 0.2760 - val_loss: 2.5975 - val_acc: 0.1750\n",
      "Epoch 4/8\n",
      "1500/1500 [==============================] - 28s - loss: 2.0995 - acc: 0.3100 - val_loss: 2.6254 - val_acc: 0.1760\n",
      "Epoch 5/8\n",
      "1500/1500 [==============================] - 28s - loss: 2.0135 - acc: 0.3333 - val_loss: 2.6011 - val_acc: 0.1890\n",
      "Epoch 6/8\n",
      "1500/1500 [==============================] - 27s - loss: 1.9100 - acc: 0.3707 - val_loss: 2.5602 - val_acc: 0.1940\n",
      "Epoch 7/8\n",
      "1500/1500 [==============================] - 28s - loss: 1.8229 - acc: 0.4000 - val_loss: 2.5027 - val_acc: 0.2020\n",
      "Epoch 8/8\n",
      "1500/1500 [==============================] - 30s - loss: 1.7694 - acc: 0.3973 - val_loss: 2.4316 - val_acc: 0.2250\n",
      "Epoch 1/12\n",
      "1500/1500 [==============================] - 35s - loss: 1.6941 - acc: 0.4393 - val_loss: 2.3633 - val_acc: 0.2360\n",
      "Epoch 2/12\n",
      "1500/1500 [==============================] - 29s - loss: 1.6623 - acc: 0.4500 - val_loss: 2.2845 - val_acc: 0.2490\n",
      "Epoch 3/12\n",
      "1500/1500 [==============================] - 28s - loss: 1.6328 - acc: 0.4540 - val_loss: 2.1273 - val_acc: 0.2920\n",
      "Epoch 4/12\n",
      "1500/1500 [==============================] - 27s - loss: 1.5758 - acc: 0.4660 - val_loss: 1.9997 - val_acc: 0.3400\n",
      "Epoch 5/12\n",
      "1500/1500 [==============================] - 28s - loss: 1.5223 - acc: 0.4853 - val_loss: 1.9019 - val_acc: 0.3490\n",
      "Epoch 6/12\n",
      "1500/1500 [==============================] - 26s - loss: 1.5077 - acc: 0.5133 - val_loss: 1.8007 - val_acc: 0.3980\n",
      "Epoch 7/12\n",
      "1500/1500 [==============================] - 28s - loss: 1.4262 - acc: 0.5307 - val_loss: 1.6824 - val_acc: 0.4170\n",
      "Epoch 8/12\n",
      "1500/1500 [==============================] - 32s - loss: 1.4372 - acc: 0.5067 - val_loss: 1.5306 - val_acc: 0.4900\n",
      "Epoch 9/12\n",
      "1500/1500 [==============================] - 29s - loss: 1.3352 - acc: 0.5353 - val_loss: 1.4458 - val_acc: 0.5200\n",
      "Epoch 10/12\n",
      "1500/1500 [==============================] - 27s - loss: 1.3820 - acc: 0.5360 - val_loss: 1.3900 - val_acc: 0.5250\n",
      "Epoch 11/12\n",
      "1500/1500 [==============================] - 31s - loss: 1.3420 - acc: 0.5553 - val_loss: 1.3422 - val_acc: 0.5350\n",
      "Epoch 12/12\n",
      "1500/1500 [==============================] - 31s - loss: 1.3015 - acc: 0.5700 - val_loss: 1.3030 - val_acc: 0.5370\n",
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 36s - loss: 1.2574 - acc: 0.5833 - val_loss: 1.2483 - val_acc: 0.5780\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 30s - loss: 1.2422 - acc: 0.5933 - val_loss: 1.2204 - val_acc: 0.5850\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 30s - loss: 1.1999 - acc: 0.6127 - val_loss: 1.1862 - val_acc: 0.5840\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 30s - loss: 1.1940 - acc: 0.6113 - val_loss: 1.1132 - val_acc: 0.6220\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 28s - loss: 1.1984 - acc: 0.6107 - val_loss: 1.0824 - val_acc: 0.6350\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 30s - loss: 1.1142 - acc: 0.6313 - val_loss: 1.0421 - val_acc: 0.6640\n",
      "Epoch 7/40\n",
      "1500/1500 [==============================] - 27s - loss: 1.0990 - acc: 0.6500 - val_loss: 1.0284 - val_acc: 0.6470\n",
      "Epoch 8/40\n",
      "1500/1500 [==============================] - 28s - loss: 1.1301 - acc: 0.6367 - val_loss: 1.0188 - val_acc: 0.6570\n",
      "Epoch 9/40\n",
      "1500/1500 [==============================] - 29s - loss: 1.1121 - acc: 0.6267 - val_loss: 0.9791 - val_acc: 0.6890\n",
      "Epoch 10/40\n",
      "1500/1500 [==============================] - 26s - loss: 1.0651 - acc: 0.6553 - val_loss: 0.9588 - val_acc: 0.6990\n",
      "Epoch 11/40\n",
      "1500/1500 [==============================] - 32s - loss: 1.0455 - acc: 0.6600 - val_loss: 0.9629 - val_acc: 0.6910\n",
      "Epoch 12/40\n",
      "1500/1500 [==============================] - 30s - loss: 1.0133 - acc: 0.6840 - val_loss: 0.9785 - val_acc: 0.6650\n",
      "Epoch 13/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.9909 - acc: 0.6747 - val_loss: 0.9796 - val_acc: 0.6450\n",
      "Epoch 14/40\n",
      "1500/1500 [==============================] - 27s - loss: 1.0119 - acc: 0.6720 - val_loss: 0.9245 - val_acc: 0.6950\n",
      "Epoch 15/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.9735 - acc: 0.6933 - val_loss: 0.9595 - val_acc: 0.6550\n",
      "Epoch 16/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.9725 - acc: 0.6800 - val_loss: 0.8825 - val_acc: 0.6950\n",
      "Epoch 17/40\n",
      "1500/1500 [==============================] - 30s - loss: 0.9410 - acc: 0.6987 - val_loss: 0.8775 - val_acc: 0.6920\n",
      "Epoch 18/40\n",
      "1500/1500 [==============================] - 30s - loss: 0.9369 - acc: 0.6947 - val_loss: 0.8421 - val_acc: 0.7130\n",
      "Epoch 19/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.9007 - acc: 0.7180 - val_loss: 0.7887 - val_acc: 0.7550\n",
      "Epoch 20/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.9174 - acc: 0.7073 - val_loss: 0.7499 - val_acc: 0.7890\n",
      "Epoch 21/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.9398 - acc: 0.6987 - val_loss: 0.7391 - val_acc: 0.7850\n",
      "Epoch 22/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.8870 - acc: 0.7240 - val_loss: 0.7758 - val_acc: 0.7670\n",
      "Epoch 23/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.8679 - acc: 0.7400 - val_loss: 0.7945 - val_acc: 0.7610\n",
      "Epoch 24/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.8617 - acc: 0.7213 - val_loss: 0.7942 - val_acc: 0.7610\n",
      "Epoch 25/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.8020 - acc: 0.7480 - val_loss: 0.7855 - val_acc: 0.7580\n",
      "Epoch 26/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.8098 - acc: 0.7387 - val_loss: 0.7698 - val_acc: 0.7710\n",
      "Epoch 27/40\n",
      "1500/1500 [==============================] - 30s - loss: 0.8610 - acc: 0.7207 - val_loss: 0.7250 - val_acc: 0.7960\n",
      "Epoch 28/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.8050 - acc: 0.7440 - val_loss: 0.7188 - val_acc: 0.7960\n",
      "Epoch 29/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.7964 - acc: 0.7520 - val_loss: 0.6955 - val_acc: 0.7980\n",
      "Epoch 30/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.7868 - acc: 0.7580 - val_loss: 0.7108 - val_acc: 0.7860\n",
      "Epoch 31/40\n",
      "1500/1500 [==============================] - 32s - loss: 0.7749 - acc: 0.7627 - val_loss: 0.6581 - val_acc: 0.8190\n",
      "Epoch 32/40\n",
      "1500/1500 [==============================] - 32s - loss: 0.7612 - acc: 0.7640 - val_loss: 0.6735 - val_acc: 0.7970\n",
      "Epoch 33/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.7781 - acc: 0.7527 - val_loss: 0.6494 - val_acc: 0.8100\n",
      "Epoch 34/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.7314 - acc: 0.7793 - val_loss: 0.6612 - val_acc: 0.7910\n",
      "Epoch 35/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.7421 - acc: 0.7667 - val_loss: 0.7132 - val_acc: 0.7610\n",
      "Epoch 36/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.7502 - acc: 0.7707 - val_loss: 0.6485 - val_acc: 0.8010\n",
      "Epoch 37/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.7240 - acc: 0.7813 - val_loss: 0.6637 - val_acc: 0.7990\n",
      "Epoch 38/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.7152 - acc: 0.7900 - val_loss: 0.6434 - val_acc: 0.8010\n",
      "Epoch 39/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.6772 - acc: 0.7980 - val_loss: 0.6232 - val_acc: 0.8090\n",
      "Epoch 40/40\n",
      "1500/1500 [==============================] - 32s - loss: 0.6928 - acc: 0.7913 - val_loss: 0.6480 - val_acc: 0.7930\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lowered the learning rate for the initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 33s - loss: 2.5941 - acc: 0.1933 - val_loss: 2.9657 - val_acc: 0.1110\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 26s - loss: 1.8740 - acc: 0.3827 - val_loss: 2.1067 - val_acc: 0.2240\n",
      "Epoch 1/8\n",
      "1500/1500 [==============================] - 33s - loss: 1.5833 - acc: 0.4813 - val_loss: 2.0865 - val_acc: 0.2120\n",
      "Epoch 2/8\n",
      "1500/1500 [==============================] - 26s - loss: 1.4581 - acc: 0.5120 - val_loss: 2.1686 - val_acc: 0.2550\n",
      "Epoch 3/8\n",
      "1500/1500 [==============================] - 26s - loss: 1.3412 - acc: 0.5440 - val_loss: 2.2776 - val_acc: 0.2330\n",
      "Epoch 4/8\n",
      "1500/1500 [==============================] - 26s - loss: 1.2418 - acc: 0.5893 - val_loss: 2.3216 - val_acc: 0.2450\n",
      "Epoch 5/8\n",
      "1500/1500 [==============================] - 27s - loss: 1.1302 - acc: 0.6193 - val_loss: 2.2952 - val_acc: 0.2430\n",
      "Epoch 6/8\n",
      "1500/1500 [==============================] - 28s - loss: 1.1285 - acc: 0.6340 - val_loss: 2.2841 - val_acc: 0.1980\n",
      "Epoch 7/8\n",
      "1500/1500 [==============================] - 26s - loss: 1.0593 - acc: 0.6347 - val_loss: 2.1087 - val_acc: 0.2400\n",
      "Epoch 8/8\n",
      "1500/1500 [==============================] - 27s - loss: 0.9404 - acc: 0.7000 - val_loss: 1.9855 - val_acc: 0.3300\n",
      "Epoch 1/12\n",
      "1500/1500 [==============================] - 34s - loss: 0.9205 - acc: 0.7000 - val_loss: 2.0686 - val_acc: 0.3170\n",
      "Epoch 2/12\n",
      "1500/1500 [==============================] - 29s - loss: 0.8643 - acc: 0.7173 - val_loss: 1.7426 - val_acc: 0.4050\n",
      "Epoch 3/12\n",
      "1500/1500 [==============================] - 29s - loss: 0.8340 - acc: 0.7473 - val_loss: 1.5338 - val_acc: 0.4610\n",
      "Epoch 4/12\n",
      "1500/1500 [==============================] - 27s - loss: 0.8052 - acc: 0.7453 - val_loss: 1.4590 - val_acc: 0.5420\n",
      "Epoch 5/12\n",
      "1500/1500 [==============================] - 28s - loss: 0.7751 - acc: 0.7527 - val_loss: 1.2970 - val_acc: 0.5770\n",
      "Epoch 6/12\n",
      "1500/1500 [==============================] - 27s - loss: 0.7373 - acc: 0.7667 - val_loss: 1.2292 - val_acc: 0.6320\n",
      "Epoch 7/12\n",
      "1500/1500 [==============================] - 27s - loss: 0.7161 - acc: 0.7813 - val_loss: 1.1068 - val_acc: 0.6440\n",
      "Epoch 8/12\n",
      "1500/1500 [==============================] - 27s - loss: 0.6705 - acc: 0.7993 - val_loss: 0.9341 - val_acc: 0.6950\n",
      "Epoch 9/12\n",
      "1500/1500 [==============================] - 29s - loss: 0.6632 - acc: 0.7940 - val_loss: 0.8616 - val_acc: 0.7280\n",
      "Epoch 10/12\n",
      "1500/1500 [==============================] - 27s - loss: 0.6195 - acc: 0.8193 - val_loss: 0.7213 - val_acc: 0.7640\n",
      "Epoch 11/12\n",
      "1500/1500 [==============================] - 28s - loss: 0.6065 - acc: 0.8200 - val_loss: 0.7311 - val_acc: 0.7580\n",
      "Epoch 12/12\n",
      "1500/1500 [==============================] - 29s - loss: 0.5980 - acc: 0.8333 - val_loss: 0.6193 - val_acc: 0.8050\n",
      "Epoch 1/40\n",
      "1500/1500 [==============================] - 33s - loss: 0.5801 - acc: 0.8240 - val_loss: 0.5405 - val_acc: 0.8280\n",
      "Epoch 2/40\n",
      "1500/1500 [==============================] - 31s - loss: 0.5135 - acc: 0.8460 - val_loss: 0.4715 - val_acc: 0.8760\n",
      "Epoch 3/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.5432 - acc: 0.8373 - val_loss: 0.5134 - val_acc: 0.8630\n",
      "Epoch 4/40\n",
      "1500/1500 [==============================] - 31s - loss: 0.4976 - acc: 0.8520 - val_loss: 0.5151 - val_acc: 0.8360\n",
      "Epoch 5/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.5038 - acc: 0.8547 - val_loss: 0.5126 - val_acc: 0.8520\n",
      "Epoch 6/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.4477 - acc: 0.8653 - val_loss: 0.4077 - val_acc: 0.8930\n",
      "Epoch 7/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.4584 - acc: 0.8673 - val_loss: 0.3912 - val_acc: 0.9010\n",
      "Epoch 8/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.4676 - acc: 0.8627 - val_loss: 0.3904 - val_acc: 0.9000\n",
      "Epoch 9/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.4327 - acc: 0.8667 - val_loss: 0.4547 - val_acc: 0.8630\n",
      "Epoch 10/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.4406 - acc: 0.8773 - val_loss: 0.3844 - val_acc: 0.8820\n",
      "Epoch 11/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.4275 - acc: 0.8680 - val_loss: 0.3690 - val_acc: 0.8970\n",
      "Epoch 12/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.3711 - acc: 0.8920 - val_loss: 0.3864 - val_acc: 0.8910\n",
      "Epoch 13/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.3962 - acc: 0.8887 - val_loss: 0.4319 - val_acc: 0.8650\n",
      "Epoch 14/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.3514 - acc: 0.8987 - val_loss: 0.4264 - val_acc: 0.8810\n",
      "Epoch 15/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.3516 - acc: 0.9047 - val_loss: 0.3264 - val_acc: 0.9080\n",
      "Epoch 16/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.3335 - acc: 0.9047 - val_loss: 0.3417 - val_acc: 0.8940\n",
      "Epoch 17/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.3855 - acc: 0.8820 - val_loss: 0.3394 - val_acc: 0.9140\n",
      "Epoch 18/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.3638 - acc: 0.8920 - val_loss: 0.3719 - val_acc: 0.8950\n",
      "Epoch 19/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.3336 - acc: 0.9100 - val_loss: 0.3216 - val_acc: 0.9010\n",
      "Epoch 20/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.3525 - acc: 0.8927 - val_loss: 0.3758 - val_acc: 0.8870\n",
      "Epoch 21/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.3289 - acc: 0.9160 - val_loss: 0.3016 - val_acc: 0.9120\n",
      "Epoch 22/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2904 - acc: 0.9253 - val_loss: 0.2761 - val_acc: 0.9290\n",
      "Epoch 23/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.3153 - acc: 0.9120 - val_loss: 0.3302 - val_acc: 0.9110\n",
      "Epoch 24/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.3360 - acc: 0.9033 - val_loss: 0.2966 - val_acc: 0.9060\n",
      "Epoch 25/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.3059 - acc: 0.9093 - val_loss: 0.3037 - val_acc: 0.9180\n",
      "Epoch 26/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.3143 - acc: 0.9027 - val_loss: 0.3020 - val_acc: 0.9030\n",
      "Epoch 27/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2852 - acc: 0.9213 - val_loss: 0.3881 - val_acc: 0.9030\n",
      "Epoch 28/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2750 - acc: 0.9307 - val_loss: 0.3104 - val_acc: 0.9100\n",
      "Epoch 29/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.2917 - acc: 0.9167 - val_loss: 0.2308 - val_acc: 0.9400\n",
      "Epoch 30/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.2842 - acc: 0.9233 - val_loss: 0.2562 - val_acc: 0.9410\n",
      "Epoch 31/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2726 - acc: 0.9220 - val_loss: 0.2761 - val_acc: 0.9160\n",
      "Epoch 32/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.2674 - acc: 0.9233 - val_loss: 0.2429 - val_acc: 0.9280\n",
      "Epoch 33/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2571 - acc: 0.9260 - val_loss: 0.2748 - val_acc: 0.9230\n",
      "Epoch 34/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.2555 - acc: 0.9307 - val_loss: 0.4433 - val_acc: 0.8680\n",
      "Epoch 35/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.2506 - acc: 0.9313 - val_loss: 0.2713 - val_acc: 0.9130\n",
      "Epoch 36/40\n",
      "1500/1500 [==============================] - 29s - loss: 0.2468 - acc: 0.9373 - val_loss: 0.2976 - val_acc: 0.9160\n",
      "Epoch 37/40\n",
      "1500/1500 [==============================] - 28s - loss: 0.2698 - acc: 0.9220 - val_loss: 0.3419 - val_acc: 0.8720\n",
      "Epoch 38/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2579 - acc: 0.9240 - val_loss: 0.2767 - val_acc: 0.9010\n",
      "Epoch 39/40\n",
      "1500/1500 [==============================] - 26s - loss: 0.2392 - acc: 0.9340 - val_loss: 0.2804 - val_acc: 0.9210\n",
      "Epoch 40/40\n",
      "1500/1500 [==============================] - 27s - loss: 0.2416 - acc: 0.9380 - val_loss: 0.2863 - val_acc: 0.9090\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 33s - loss: 0.2321 - acc: 0.9340 - val_loss: 0.2595 - val_acc: 0.9170\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 27s - loss: 0.2222 - acc: 0.9347 - val_loss: 0.2365 - val_acc: 0.9250\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 26s - loss: 0.2264 - acc: 0.9327 - val_loss: 0.2931 - val_acc: 0.8970\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 28s - loss: 0.2265 - acc: 0.9360 - val_loss: 0.2195 - val_acc: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdacbecd510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 35s - loss: 0.2105 - acc: 0.9487 - val_loss: 0.2287 - val_acc: 0.9240\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 27s - loss: 0.2015 - acc: 0.9433 - val_loss: 0.2157 - val_acc: 0.9370\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 28s - loss: 0.2267 - acc: 0.9387 - val_loss: 0.2233 - val_acc: 0.9350\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 26s - loss: 0.2125 - acc: 0.9433 - val_loss: 0.2322 - val_acc: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdacbec2590>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 10\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 32s - loss: 0.2173 - acc: 0.9460 - val_loss: 0.2099 - val_acc: 0.9370\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 27s - loss: 0.2016 - acc: 0.9447 - val_loss: 0.2672 - val_acc: 0.9120\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 27s - loss: 0.1887 - acc: 0.9527 - val_loss: 0.2558 - val_acc: 0.9210\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 26s - loss: 0.1916 - acc: 0.9440 - val_loss: 0.2071 - val_acc: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdacbec25d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1000\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 33s - loss: 0.1904 - acc: 0.9500 - val_loss: 0.2885 - val_acc: 0.8910\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 28s - loss: 0.1992 - acc: 0.9433 - val_loss: 0.1970 - val_acc: 0.9430\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 27s - loss: 0.1920 - acc: 0.9487 - val_loss: 0.2359 - val_acc: 0.9320\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 27s - loss: 0.1755 - acc: 0.9600 - val_loss: 0.2326 - val_acc: 0.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdacbec2c90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1000000\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.1),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                         nb_val_samples=val_batches.nb_sample)\n",
    "    return model\n",
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/aviary_005.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f9f0bd83991b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "val_batches, probs = model.test(path+'valid', batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e16f9e2d4728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "probs = probs[:,0]\n",
    "preds = np.round(1-probs)\n",
    "probs[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = val_batches.classes\n",
    "filenames = val_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4f2621e2ba57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "###### ___archive_imagenet"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
